{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint15 論文読解入門"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.このSprintについて\n",
    "\n",
    "### Sprintの目的\n",
    "機械学習分野の論文から有益な情報を引き出せるようにする\n",
    "これまで扱ってきた領域の論文から新たな知識を得る\n",
    "\n",
    "### どのように学ぶか\n",
    "ある論文に対しての問題に答えていくことで、読むポイントを学んでいきます。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.論文読解\n",
    "\n",
    "以下の論文を読み問題に答えてください。CNNを使った物体検出（Object Detection）の代表的な研究です。\n",
    "\n",
    "\n",
    "[8]Ren, S., He, K., Girshick, R., Sun, J.: Faster r-cnn: Towards real-time object detection with region proposal networks. In: Advances in neural information processing systems. (2015) 91–99\n",
    "\n",
    "\n",
    "https://arxiv.org/pdf/1506.01497.pdf\n",
    "\n",
    "# 問題\n",
    "それぞれについてJupyter Notebookにマークダウン形式で記述してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) 物体検出の分野にはどういった手法が存在したか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【回答】<br>\n",
    "領域提案アルゴリズムとして、SPPnet、Fast R-CNN、fully convolutional network（FCN）がある\n",
    "\n",
    "【該当箇所】<br>\n",
    "Advances like SPPnet [1] and Fast R-CNN [2] have reduced the running time of these detection networks, exposing region proposal computation as a bottleneck.\n",
    "\n",
    "The RPN is thus a kind of fully convo- lutional network (FCN) [7] and can be trained end-to- end specifically for the task for generating detection proposals.\n",
    "The first module is a deep fully convolutional network that proposes regions,\n",
    "\n",
    "【論文】<br>\n",
    "-  SPPnet\n",
    ">https://arxiv.org/abs/1406.4729\n",
    "\n",
    "- Fast R-CNN\n",
    ">https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Girshick_Fast_R-CNN_ICCV_2015_paper.pdf\n",
    "\n",
    "- （deep ）fully convolutional network\n",
    "> https://arxiv.org/pdf/1411.4038.pdf <br>\n",
    ">特徴：全結合層を持たず、ネットワークが畳み込み層のみで構成されている"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Fasterとあるが、どういった仕組みで高速化したのか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【回答】<br>\n",
    "検出ネットワークと全画像の畳み込み特徴を共有する点\n",
    "\n",
    "【該当箇所】<br>\n",
    "In this work, we introduce a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals.\n",
    "\n",
    "By sharing convolutional features with the down-stream detection network, the region proposal step is nearly cost-free. \n",
    "\n",
    "P4<br>\n",
    "The translation-invariant property also reduces the model size. MultiBox has a (4 + 1) × 800-dimensional fully-connected output layer, whereas our method has a (4 + 2) × 9-dimensional convolutional output layer in the case of k = 9 anchors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【補足】<br>\n",
    "2つのモジュールで構成されている<br>\n",
    "- 第1のモジュールは領域を提案する深い完全畳み込みネットワーク\n",
    "- 第2のモジュールは提案された領域を利用するFast R-CNN検出器\n",
    "\n",
    "Our object detection system, called Faster R-CNN, is composed of two modules. The first module is a deep fully convolutional network that proposes regions, and the second module is the Fast R-CNN detector [2] that uses the proposed regions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) One-Stageの手法とTwo-Stageの手法はどう違うのか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【回答】<br>\n",
    "One-Stageは画像中の物体の分類、位置特定、検出を同時に行うために畳み込みネットワークを訓練する<br>\n",
    "Two-StageはRPNで領域提案→Faster R-CNNで物体検出という流れである<br>\n",
    "\n",
    "【該当箇所】<br>\n",
    "参考文献9「OverFeat:Integrated Recognition, Localization and Detection using Convolutional Networks」より\n",
    "The main point of this paper is to show that training a convolutional network to simultaneously classify, locate and detect objects in images can boost the classification accuracy and the detection and localization accuracy of all tasks. \n",
    "\n",
    "P10<br>\n",
    "OverFeat is a one-stage, class-specific detection pipeline, and ours is a two-stage cascade consisting of class-agnostic pro- posals and class-specific detections. \n",
    "\n",
    "Though both methods use sliding windows, the region proposal task is only the first stage of Faster R- CNN—the downstream Fast R-CNN detector attends to the proposals to refine them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) RPNとは何か。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【回答】<br>\n",
    "RPNは、各位置における物体境界と物体性スコアを同時に予測する完全畳み込みネットワーク（fully convolutional network）である。\n",
    "\n",
    "【該当箇所】<br>\n",
    "An RPN is a fully convolutional network that simultaneously predicts object bounds and objectness scores at each position. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5) RoIプーリングとは何か。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【回答】\n",
    "- RoI max pooling は、h × w RoI win-down を H × W グリッドに分割して、おおよそのサイズ h/H × w/W のサブウィンドウを作成し、各サブウィンドウ内の値を対応する出力グリッドセルに max-pooling することで動作します。\n",
    "- RoI層は、Spatial Pyramid Pooling Netで使用されているSpatial Pyramid Pooling層の特別なケースであり、ピラミッドレベルは1つだけです。\n",
    "- RoIはRegion of Interestの略\n",
    "- SPPはSpatial Pyramid Poolingの略\n",
    "\n",
    "参考文献2「Fast R-CNN」より引用<br>\n",
    "RoI max pooling works by dividing the h × w RoI win- dow into an H × W grid of sub-windows of approximate size h/H × w/W and then max-pooling the values in each sub-window into the corresponding output grid cell.\n",
    "\n",
    "The RoI layer is simply the special-case of the spatial pyramid pooling layer used in SPPnets [11] in which there is only one pyramid level. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (6) Anchorのサイズはどうするのが適切か。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【回答】<br>\n",
    "3 scales with 3 aspect ratios\n",
    "\n",
    "【該当箇所】<br>\n",
    "P9<br>\n",
    "Using just 3 scales with 1 aspect ratio (69.8%) is as good as using 3 scales with 3 aspect ratios on this dataset, suggesting that scales and aspect ratios are not disentangled dimensions for the detection accuracy. But we still adopt these two dimensions in our designs to keep our system flexible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (7) 何というデータセットを使い、先行研究に比べどういった指標値が得られているか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【回答】<br>\n",
    "- データセットの種類：PASCAL VOC 2007<br>\n",
    "SS（Selective Search） propsals 2000 mAP 58.7<br>\n",
    "EB（EdgeBoxes） propsals 2000 58.6<br>\n",
    "RPN（Region Proposal Network）+ZF（Zeiler and Fergus model）+,shared propsals 300 59.9 <br>\n",
    "\n",
    "we may expect RPN+VGG to be better than SS. The following experiments justify this hy- pothesis.\n",
    "\n",
    "- データセットの種類：MS COCO<br>\n",
    "Faster R-CNNシステムの評価　table11<br>\n",
    "Faster R-CNN：mAP@0.5が42.1%、mAP@[.5, .95]が21.5%<br>\n",
    "Fast R- CNN ：mAP@0.5が39.3％、mAP@[.5, .95]が19.3%<br>\n",
    "\n",
    "Next we evaluate our Faster R-CNN system. Using the COCO training set to train, Faster R-CNN has 42.1% mAP@0.5 and 21.5% mAP@[.5, .95] on the COCO test-dev set. This is 2.8% higher for mAP@0.5 and 2.2% higher for mAP@[.5, .95] than the Fast R- CNN counterpart under the same protocol (Table 11). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 補足\n",
    "Faster R-CNNよりも新しい物体検出の論文\n",
    "\n",
    "- SSD\n",
    "\n",
    "-  YOLO9000\n",
    "\n",
    "- Masked R-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "226.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
