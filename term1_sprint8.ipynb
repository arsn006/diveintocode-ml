{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# term1 アンサンブル学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.このSprintについて\n",
    "### Sprintの目的\n",
    "アンサンブル学習について理解する\n",
    "\n",
    "### どのように学ぶか\n",
    "スクラッチでアンサンブル学習の各種手法を実装していきます\n",
    "## 2.アンサンブル学習\n",
    "3種類のアンサンブル学習をスクラッチ実装していきます。そして、それぞれの効果を小さめのデータセットで確認します。\n",
    "\n",
    "\n",
    "- ブレンディング\n",
    "- バギング\n",
    "- スタッキング\n",
    "\n",
    "### 小さなデータセットの用意\n",
    "以前も利用した回帰のデータセットを用意します。\n",
    "\n",
    "\n",
    "House Prices: Advanced Regression Techniques\n",
    "\n",
    "\n",
    "この中のtrain.csvをダウンロードし、目的変数としてSalePrice、説明変数として、GrLivAreaとYearBuiltを使います。\n",
    "\n",
    "\n",
    "train.csvを学習用（train）8割、検証用（val）2割に分割してください。\n",
    "\n",
    "### scikit-learn\n",
    "単一のモデルはスクラッチ実装ではなく、scikit-learnなどのライブラリの使用を推奨します。\n",
    "\n",
    "sklearn.linear_model.LinearRegression — scikit-learn 0.21.3 documentation\n",
    "\n",
    "\n",
    "sklearn.svm.SVR — scikit-learn 0.21.3 documentation\n",
    "\n",
    "\n",
    "sklearn.tree.DecisionTreeRegressor — scikit-learn 0.21.3 documentation\n",
    "\n",
    "## 3.ブレンディング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題1】ブレンディングのスクラッチ実装\n",
    "ブレンディング をスクラッチ実装し、単一モデルより精度があがる例を 最低3つ 示してください。精度があがるとは、検証用データに対する平均二乗誤差（MSE）が小さくなることを指します。\n",
    "\n",
    "### ブレンディングとは\n",
    "ブレンディングとは、N個の多様なモデルを独立して学習させ、推定結果を重み付けした上で足し合わせる方法です。最も単純には平均をとります。多様なモデルとは、以下のような条件を変化させることで作り出すものです。\n",
    "\n",
    "\n",
    "- 手法（例：線形回帰、SVM、決定木、ニューラルネットワークなど）\n",
    "- ハイパーパラメータ（例：SVMのカーネルの種類、重みの初期値など）\n",
    "- 入力データの前処理の仕方（例：標準化、対数変換、PCAなど）\n",
    "\n",
    "重要なのはそれぞれのモデルが大きく異なることです。\n",
    "\n",
    "\n",
    "回帰問題でのブレンディングは非常に単純であるため、scikit-learnには用意されていません。\n",
    "\n",
    "\n",
    "《補足》\n",
    "\n",
    "\n",
    "分類問題の場合は、多数決を行います。回帰問題に比べると複雑なため、scikit-learnにはVotingClassifierが用意されています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:.6f}'.format\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "index_array = df.columns\n",
    "index_list = index_array.tolist()\n",
    "index_list.remove(\"GrLivArea\")\n",
    "index_list.remove(\"YearBuilt\")\n",
    "index_list.remove(\"SalePrice\")\n",
    "df.drop(columns=index_list, inplace=True)\n",
    "#df.columns\n",
    "X = df.iloc[:, :2].values\n",
    "y = df.iloc[:, 2:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yには対数変換をかけておく\n",
    "y = np.log(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arisa/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# 標準化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_std = scaler.transform(X_train)\n",
    "X_val_std = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(292, 1)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 線形回帰 学習と推定\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linear_model = LinearRegression().fit(X_train_std, y_train)\n",
    "yp_linear = linear_model.predict(X_val_std)\n",
    "yp_linear.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arisa/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(292,)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM 学習と推定\n",
    "from sklearn.svm import SVR\n",
    "svr_model = SVR()\n",
    "svr_model.fit(X_train_std, y_train)\n",
    "yp_svr = svr_model.predict(X_val_std)\n",
    "yp_svr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(292,)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 決定木 学習と推定\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "d_tree_model = DecisionTreeRegressor()\n",
    "d_tree_model.fit(X_train_std, y_train)\n",
    "yp_d_tree = d_tree_model.predict(X_val_std)\n",
    "yp_d_tree.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 平均二乗誤差で評価\n",
    "from sklearn.metrics import mean_squared_error\n",
    "error_linear = mean_squared_error(y_val, yp_linear)\n",
    "error_svr = mean_squared_error(y_val, yp_svr)\n",
    "error_d_tree = mean_squared_error(y_val, yp_d_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 表作成用\n",
    "error_df = pd.DataFrame({\"LinearRegression\":[error_linear], \"SVM\" : [error_svr], \"決定木\" : [error_d_tree]},\n",
    "                        index=[\"平均二乗誤差\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LinearRegression</th>\n",
       "      <th>SVM</th>\n",
       "      <th>決定木</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>平均二乗誤差</th>\n",
       "      <td>0.036798</td>\n",
       "      <td>0.035652</td>\n",
       "      <td>0.058852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        LinearRegression      SVM      決定木\n",
       "平均二乗誤差          0.036798 0.035652 0.058852"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(292,)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " yp_d_tree.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(292,)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 線型回帰とSVM、決定木を足して平均を取る\n",
    "LSDt_yp = np.concatenate([yp_linear.reshape(len(yp_linear), 1), yp_svr.reshape(len(yp_svr), 1 ),\n",
    "                          yp_d_tree.reshape(len(yp_d_tree),1)], 1)\n",
    "\n",
    "LSDt_mean = np.mean(LSDt_yp, 1)\n",
    "LSDt_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 平均二乗誤差で評価\n",
    "error_LSDt_m = mean_squared_error(y_val, LSDt_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LinearRegression</th>\n",
       "      <th>SVM</th>\n",
       "      <th>決定木</th>\n",
       "      <th>線型SVM決定木</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>平均二乗誤差</th>\n",
       "      <td>0.036798</td>\n",
       "      <td>0.035652</td>\n",
       "      <td>0.058852</td>\n",
       "      <td>0.033961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        LinearRegression      SVM      決定木  線型SVM決定木\n",
       "平均二乗誤差          0.036798 0.035652 0.058852  0.033961"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_df = error_df.assign(線型SVM決定木=[error_LSDt_m])\n",
    "error_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(292,)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.array([0.3, 0.5, 0.2])\n",
    "LSDt_w_yp = np.average(LSDt_yp, axis=1 ,weights=w)\n",
    "LSDt_w_yp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 平均二乗誤差で評価\n",
    "error_LSDt_wm = mean_squared_error(y_val, LSDt_w_yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LinearRegression</th>\n",
       "      <th>SVM</th>\n",
       "      <th>決定木</th>\n",
       "      <th>線型SVM決定木</th>\n",
       "      <th>線S木w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>平均二乗誤差</th>\n",
       "      <td>0.036798</td>\n",
       "      <td>0.035652</td>\n",
       "      <td>0.058852</td>\n",
       "      <td>0.033961</td>\n",
       "      <td>0.033209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        LinearRegression      SVM      決定木  線型SVM決定木     線S木w\n",
       "平均二乗誤差          0.036798 0.035652 0.058852  0.033961 0.033209"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_df = error_df.assign(線S木w=[error_LSDt_wm])\n",
    "error_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(292,)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 線型回帰とSVMを足して平均を取る\n",
    "LS_yp = np.concatenate([yp_linear.reshape(len(yp_linear), 1), yp_svr.reshape(len(yp_svr), 1 )], 1)\n",
    "LS_mean = np.mean(LS_yp, 1)\n",
    "LS_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 平均二乗誤差で評価\n",
    "error_LS_m = mean_squared_error(y_val, LS_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LinearRegression</th>\n",
       "      <th>SVM</th>\n",
       "      <th>決定木</th>\n",
       "      <th>線型SVM決定木</th>\n",
       "      <th>線S木w</th>\n",
       "      <th>線S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>平均二乗誤差</th>\n",
       "      <td>0.036798</td>\n",
       "      <td>0.035652</td>\n",
       "      <td>0.058852</td>\n",
       "      <td>0.033961</td>\n",
       "      <td>0.033209</td>\n",
       "      <td>0.034751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        LinearRegression      SVM      決定木  線型SVM決定木     線S木w       線S\n",
       "平均二乗誤差          0.036798 0.035652 0.058852  0.033961 0.033209 0.034751"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_df = error_df.assign(線S=[error_LS_m])\n",
    "error_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "線型回帰、SVM、決定木の単体モデルの平均二乗誤差と、<br>\n",
    "①3つのモデル（線型回帰、SVM、決定木）の平均<br>\n",
    "②3つのモデル（線型回帰、SVM、決定木）の加重平均<br>\n",
    "③２つのモデル（線型回帰、SVM）の平均で比較をした<br>\n",
    "\n",
    "【考察】<br>\n",
    "単体に比べ①〜③全てで平均二乗誤差が小さくなった。\n",
    "成績の良かった２つのモデルの平均より、少し成績が悪くても３つのモデルの平均を取った方が平均二乗誤差が小さくなった。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.バギング\n",
    "### 【問題2】バギングのスクラッチ実装\n",
    "バギング をスクラッチ実装し、単一モデルより精度があがる例を 最低1つ 示してください。\n",
    "\n",
    "### バギングとは\n",
    "バギングは入力データの選び方を多様化する方法です。学習データから重複を許した上でランダムに抜き出すことで、N種類のサブセット（ ブートストラップサンプル ）を作り出します。それらによってモデルをN個学習し、推定結果の平均をとります。ブレンディングと異なり、それぞれの重み付けを変えることはありません。\n",
    "\n",
    "sklearn.model_selection.train_test_split — scikit-learn 0.21.3 documentation\n",
    "\n",
    "\n",
    "scikit-learnのtrain_test_splitを、shuffleパラメータをTrueにして使うことで、ランダムにデータを分割することができます。これによりブートストラップサンプルが手に入ります。\n",
    "\n",
    "\n",
    "推定結果の平均をとる部分はブースティングと同様の実装になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagging_func(n, X_train_std, y_train, X_val_std):\n",
    "    for i in range(n):\n",
    "        X_t, X_v, y_t, y_v = train_test_split(X_train_std, y_train, test_size=0.2, shuffle=True)\n",
    "        # X_train_stdの一部を学習\n",
    "        model = DecisionTreeRegressor()\n",
    "        model.fit(X_t, y_t)\n",
    "        # X_val_stdから予測\n",
    "        yp_v = model.predict(X_val_std)\n",
    "        if i == 0:\n",
    "            yp_all = yp_v.reshape(len(yp_v),1)\n",
    "        else:\n",
    "            yp_all = np.concatenate([yp_all,yp_v.reshape(len(yp_v),1)], 1)\n",
    "    #print(\"yp_all.shape\", yp_all.shape)       \n",
    "    yp_mean = np.mean(yp_all, 1)\n",
    "    #print(\"yp_mean\", yp_mean)\n",
    "    return yp_mean        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_yp_1 = bagging_func(1, X_train_std, y_train, X_val_std)\n",
    "bagging_yp_5 = bagging_func(5, X_train_std, y_train, X_val_std)\n",
    "bagging_yp_10 = bagging_func(10, X_train_std, y_train, X_val_std)\n",
    "bagging_yp_20 = bagging_func(20, X_train_std, y_train, X_val_std)\n",
    "bagging_yp_50 = bagging_func(50, X_train_std, y_train, X_val_std)\n",
    "bagging_yp_100 = bagging_func(100, X_train_std, y_train, X_val_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_bg_1 = mean_squared_error(y_val, bagging_yp_1)\n",
    "error_bg_5 = mean_squared_error(y_val, bagging_yp_5)\n",
    "error_bg_10 = mean_squared_error(y_val, bagging_yp_10)\n",
    "error_bg_20 = mean_squared_error(y_val, bagging_yp_20)\n",
    "error_bg_100 = mean_squared_error(y_val, bagging_yp_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 表作成用\n",
    "error_bg_df = pd.DataFrame({\"1回\" : [error_bg_1], \"5回\":[error_bg_5], \"10回\" : [error_bg_10],\n",
    "                         \"20回\" : [error_bg_20], \"50回\" : [error_bg_50], \"100回\" : [error_bg_100]},\n",
    "                        index=[\"平均二乗誤差\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1回</th>\n",
       "      <th>5回</th>\n",
       "      <th>10回</th>\n",
       "      <th>20回</th>\n",
       "      <th>50回</th>\n",
       "      <th>100回</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>平均二乗誤差</th>\n",
       "      <td>0.059500</td>\n",
       "      <td>0.044653</td>\n",
       "      <td>0.042090</td>\n",
       "      <td>0.039258</td>\n",
       "      <td>0.039075</td>\n",
       "      <td>0.039590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             1回       5回      10回      20回      50回     100回\n",
       "平均二乗誤差 0.059500 0.044653 0.042090 0.039258 0.039075 0.039590"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_bg_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【考察】<br>\n",
    "５０回まではサンプルを増やすと良い結果が得られたが、100回では少し精度が下がった。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.スタッキング\n",
    "### 【問題3】スタッキングのスクラッチ実装\n",
    "スタッキング をスクラッチ実装し、単一モデルより精度があがる例を 最低1つ 示してください。\n",
    "\n",
    "### スタッキングとは\n",
    "スタッキングの手順は以下の通りです。最低限ステージ0とステージ1があればスタッキングは成立するため、それを実装してください。まずは $K_0=3, M_0=2$ 程度にします。\n",
    "\n",
    "《学習時》\n",
    "\n",
    "\n",
    "（ステージ $0$ ）\n",
    "\n",
    "\n",
    "学習データを $K_0$ 個に分割する。\n",
    "分割した内の $(K_0 - 1)$ 個をまとめて学習用データ、残り $1$ 個を推定用データとする組み合わせが $K_0$ 個作れる。\n",
    "あるモデルのインスタンスを $K_0$ 個用意し、異なる学習用データを使い学習する。\n",
    "それぞれの学習済みモデルに対して、使っていない残り $1$ 個の推定用データを入力し、推定値を得る。（これをブレンドデータと呼ぶ）\n",
    "さらに、異なるモデルのインスタンスも $K_0$ 個用意し、同様のことを行う。モデルが $M_0$ 個あれば、 $M_0$ 個のブレンドデータが得られる。\n",
    "\n",
    "（ステージ $n$ ）\n",
    "\n",
    "\n",
    "ステージ $n-1$ のブレンドデータを$M_{n-1}$ 次元の特徴量を持つ学習用データと考え、 $K_n$ 個に分割する。以下同様である。\n",
    "\n",
    "（ステージ $N$ ）＊最後のステージ\n",
    "\n",
    "\n",
    "ステージ $N-1$ の $M_{N-1}$ 個のブレンドデータを$M_{N-1}$ 次元の特徴量の入力として、1種類のモデルの学習を行う。これが最終的な推定を行うモデルとなる。\n",
    "\n",
    "《推定時》\n",
    "\n",
    "\n",
    "（ステージ $0$ ）\n",
    "\n",
    "\n",
    "テストデータを $K_0×M_0$ 個の学習済みモデルに入力し、$K_0×M_0$ 個の推定値を得る。これを $K_0$ の軸で平均値を求め $M_0$ 次元の特徴量を持つデータを得る。（ブレンドテストと呼ぶ）\n",
    "\n",
    "（ステージ $n$ ）\n",
    "\n",
    "\n",
    "ステージ $n-1$ で得たブレンドテストを $K_n×M_n$ 個の学習済みモデルに入力し、$K_n×M_n$ 個の推定値を得る。これを $K_n$ の軸で平均値を求め $M_0$ 次元の特徴量を持つデータを得る。（ブレンドテストと呼ぶ）\n",
    "\n",
    "（ステージ $N$ ）＊最後のステージ\n",
    "\n",
    "\n",
    "ステージ $N-1$ で得たブレンドテストを学習済みモデルに入力し、推定値を得る。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arisa/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "K=3\n",
    "# 学習フェーズ 1層目\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=K, shuffle=True, random_state=71)\n",
    "m_instance_list = []\n",
    "va_index = []\n",
    "count = 0\n",
    "for tr_idx, va_idx in kf.split(X_train_std):\n",
    "    tr_x, va_x = X_train_std[tr_idx], X_train_std[va_idx]\n",
    "    tr_y, va_y = y_train[tr_idx], y_train[va_idx]\n",
    "    # 線型回帰\n",
    "    lin_model = LinearRegression()\n",
    "    lin_model.fit(tr_x, tr_y)\n",
    "    lin_pred = lin_model.predict(va_x)\n",
    "    \n",
    "    #決定木\n",
    "    dt_model = DecisionTreeRegressor()\n",
    "    dt_model.fit(tr_x, tr_y)\n",
    "    dt_pred = dt_model.predict(va_x)\n",
    "    \n",
    "    #SVM\n",
    "    sv_model = SVR()\n",
    "    sv_model.fit(tr_x, tr_y)\n",
    "    sv_pred = sv_model.predict(va_x)\n",
    "    \n",
    "    # インスタンスの保存\n",
    "    m_instance_list.append(lin_model)\n",
    "    m_instance_list.append(dt_model)\n",
    "    m_instance_list.append(sv_model)\n",
    "    \n",
    "    # valのindexの保存\n",
    "    va_index.append(va_idx)\n",
    "    \n",
    "    # ブレンドデータの作成\n",
    "    if count == 0:\n",
    "        lin_pred_all = lin_pred.reshape(len(lin_pred),1)\n",
    "        dt_pred_all = dt_pred.reshape(len(dt_pred),1)\n",
    "        sv_pred_all = sv_pred.reshape(len(sv_pred),1)\n",
    "    else:\n",
    "        lin_pred_all = np.concatenate([lin_pred_all,lin_pred.reshape(len(lin_pred),1)], 0)\n",
    "        dt_pred_all = np.concatenate([dt_pred_all,dt_pred.reshape(len(dt_pred),1)], 0)\n",
    "        sv_pred_all = np.concatenate([sv_pred_all,sv_pred.reshape(len(sv_pred),1)], 0)\n",
    "    \n",
    "    count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexのリストを1つのデータに\n",
    "va_index = np.concatenate(va_index)\n",
    "# 各モデルのブレンドデータも結合\n",
    "m_preds = np.concatenate([lin_pred_all, dt_pred_all, sv_pred_all], 1)\n",
    "# 順番に並べるためのindexを返す\n",
    "order = np.argsort(va_index)\n",
    "# ブレンドデータを元のサンプルの順番に並べ直す\n",
    "m_pred_all = m_preds[order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arisa/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学習フェーズ 最終層\n",
    "svm_model = SVR()\n",
    "svm_model.fit(m_pred_all, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推論フェーズ\n",
    "for i in range(K):\n",
    "    # インスタンスを取り出す\n",
    "    lin_m = m_instance_list[i]\n",
    "    dt_m = m_instance_list[i + 1]\n",
    "    sv_m = m_instance_list[i + 2]\n",
    "    \n",
    "    # 予測\n",
    "    lin_p = lin_m.predict(X_val_std)\n",
    "    dt_p = dt_m.predict(X_val_std)\n",
    "    sv_p = sv_m.predict(X_val_std)\n",
    "    \n",
    "    # 各モデルのバリデーション分の予測データを作成\n",
    "    if i == 0:\n",
    "        lin_p_all = lin_p.reshape(len(lin_p),1)\n",
    "        dt_p_all = dt_p.reshape(len(dt_p),1)\n",
    "        sv_p_all = sv_p.reshape(len(sv_p),1)\n",
    "    else:\n",
    "        lin_p_all = np.concatenate([lin_p_all,lin_p.reshape(len(lin_p),1)], 1)\n",
    "        dt_p_all = np.concatenate([dt_p_all,dt_p.reshape(len(dt_p),1)], 1)\n",
    "        sv_p_all = np.concatenate([sv_p_all,sv_p.reshape(len(sv_p),1)], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(292, 3)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_p_m = np.mean(lin_p_all, 1)\n",
    "dt_p_m = np.mean(dt_p_all, 1)\n",
    "sv_p_m = np.mean(sv_p_all, 1)\n",
    "#p_all = np.concatenate([lin_p_m.reshape(len(lin_p_m), 1), dt_p_m.reshape(len(dt_p_m), 1)], 1)\n",
    "p_all = np.concatenate([lin_p_m.reshape(len(lin_p_m), 1), dt_p_m.reshape(len(dt_p_m), 1),\n",
    "                       sv_p_m.reshape(len(sv_p_m), 1)], 1)\n",
    "p_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推論フェーズ ラストステージ\n",
    "stacking_yp = svm_model.predict(p_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(292,)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking_yp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 平均二乗誤差で評価\n",
    "error_stacking = mean_squared_error(y_val, stacking_yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_stacking_df = pd.DataFrame({\"LinearRegression\":[error_linear], \"SVM\" : [error_svr],\n",
    "                         \"決定木\" : [error_d_tree], \"Stacking\" : [error_stacking]},\n",
    "                        index=[\"平均二乗誤差\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LinearRegression</th>\n",
       "      <th>SVM</th>\n",
       "      <th>決定木</th>\n",
       "      <th>Stacking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>平均二乗誤差</th>\n",
       "      <td>0.036798</td>\n",
       "      <td>0.035652</td>\n",
       "      <td>0.058852</td>\n",
       "      <td>0.031665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        LinearRegression      SVM      決定木  Stacking\n",
       "平均二乗誤差          0.036798 0.035652 0.058852  0.031665"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_stacking_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【考察】<br>\n",
    "スタッキング（1層目：線型回帰、SVM、決定木　2層目：SVM）を行った結果、単一モデルより精度が高くなった"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
