{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint 機械学習スクラッチ入門"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【目的】機械学習スクラッチの準備をする\n",
    "\n",
    "【概要】今後の機械学習スクラッチ課題で作成するモデルを、scikit-learnを用いて一度動かしておきます。これまでの復習を兼ねたスクラッチ課題の準備です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】train_test_splitのスクラッチ\n",
    "スクラッチの練習として、scikit-learnのtrain_test_splitを自作してみます。以下の雛形をベースとして関数を完成させてください。<br>\n",
    "なお、作成した関数がscikit-learnのtrain_test_splitと同じ動作をしているか必ず確認をするようにしましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scratch_train_test_split(X, y, train_size=0.8, random_state=None, shuffle=True):\n",
    "    \"\"\"\n",
    "    検証データを分割する\n",
    "    Parameters\n",
    "    --------------\n",
    "    X : 次の形のndarray, shape(n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape(n_samples, )\n",
    "      正解値\n",
    "    train_size : float (0 <train_saize<1)\n",
    "      何割をtrainとするか指定\n",
    "    random_state : int\n",
    "      分割の前にデータをシャッフルする場合の制御値\n",
    "    shuffle : boolean\n",
    "      シャッフルするかどうか\n",
    "    \n",
    "    Returns\n",
    "    --------------\n",
    "    X_train : 次の形のndarray, shape(n_samples, n_features)\n",
    "      訓練データ\n",
    "    X_test : 次の形のndarray, shape(n_samples, n_features)\n",
    "      検証データ\n",
    "    y_train : 次の形のndarray, shape(n_samples, )\n",
    "      訓練データの正解値\n",
    "    y_test : 次の形のndarray, shape(n_samples, )\n",
    "      検証データの正解値\n",
    "    \"\"\"\n",
    "    \n",
    "    # データのサイズのみチェック\n",
    "    # yがrangeやlistで来ても対応できるようにndarrayに変換\n",
    "    y = np.array(list(y))\n",
    "    assert X.shape[0] == y.shape[0], \"size error\"\n",
    "    \n",
    "    # シャッフル用のNo.生成\n",
    "    number_ndarray = np.arange(y.shape[0])\n",
    "    \n",
    "    # シード値を入れる\n",
    "    if random_state != None:\n",
    "        random.seed(random_state)\n",
    "    \n",
    "    if shuffle == True:\n",
    "        # No.をシャッフル\n",
    "        random.shuffle(number_ndarray)\n",
    "        \n",
    "    # No.とXとyを結合\n",
    "    number_ndarray = number_ndarray.reshape(X.shape[0], 1)\n",
    "    y = y.reshape(X.shape[0], 1)\n",
    "    \n",
    "    all_ndarray = np.concatenate((number_ndarray, X, y), axis=1)\n",
    "    \n",
    "    # No.(0列目を基準に)でソート\n",
    "    index = np.argsort(all_ndarray[:, 0])\n",
    "    all_ndarray_sort = all_ndarray[index, :]\n",
    "    \n",
    "    # 分割\n",
    "    split_i = round(all_ndarray_sort.shape[0]*train_size)\n",
    "    #X_train, X_test, y_train, y_test\n",
    "    return  (all_ndarray_sort[:split_i, 1:-1], all_ndarray_sort[split_i:, 1:-1],\n",
    "    all_ndarray_sort[:split_i, -1:].reshape(split_i,), \n",
    "    all_ndarray_sort[split_i:, -1:].reshape(all_ndarray_sort.shape[0] - split_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y = np.arange(20).reshape((10, 2)), range(10)\n",
    "X = np.arange(20).reshape((10, 2))\n",
    "y = np.arange(10).reshape((10, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arisa/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# train_test_splitの挙動を確認\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, random_state=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---X_train---\n",
      "[[ 0  1]\n",
      " [ 2  3]\n",
      " [ 4  5]\n",
      " [ 6  7]\n",
      " [ 8  9]\n",
      " [10 11]\n",
      " [12 13]]\n",
      "---X_test---\n",
      "[[14 15]\n",
      " [16 17]\n",
      " [18 19]]\n",
      "---y_train---\n",
      "[0 1 2 3 4 5 6]\n",
      "---y_test---\n",
      "[7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# rain_test_splitの戻り値を確認\n",
    "print(\"---X_train---\")\n",
    "print(X_train)\n",
    "print(\"---X_test---\")\n",
    "print(X_test)\n",
    "print(\"---y_train---\")\n",
    "print(y_train)\n",
    "print(\"---y_test---\")\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1]\n",
      " [ 2  3]\n",
      " [ 4  5]\n",
      " [ 6  7]\n",
      " [ 8  9]\n",
      " [10 11]\n",
      " [12 13]\n",
      " [14 15]\n",
      " [16 17]\n",
      " [18 19]]\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "---X_train---\n",
      "[[12 13]\n",
      " [16 17]\n",
      " [18 19]\n",
      " [10 11]\n",
      " [14 15]\n",
      " [ 8  9]\n",
      " [ 0  1]]\n",
      "---X_test---\n",
      "[[6 7]\n",
      " [2 3]\n",
      " [4 5]]\n",
      "---y_train---\n",
      "[6 8 9 5 7 4 0]\n",
      "---y_test---\n",
      "[3 1 2]\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(y)\n",
    "X_train, X_test, y_train, y_test = scratch_train_test_split(X, y, train_size=0.7, random_state=1)\n",
    "print(\"---X_train---\")\n",
    "print(X_train)\n",
    "print(\"---X_test---\")\n",
    "print(X_test)\n",
    "print(\"---y_train---\")\n",
    "print(y_train)\n",
    "print(\"---y_test---\")\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_test_splitのスクラッチをした。random_stateのシード値で結果が固定されること、shuffleがTrueのとき、データがシャッフルされることも確認した。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】 分類問題を解くコードの作成\n",
    "3種類の手法（ロジスティック回帰、SVM、決定木）で<br>\n",
    "3種類のデータセット（irisのvirgicolorとvirginica特徴量は全て、シンプルデータセット1、シンプルデータセット2）を学習・推定するコードを作成してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = datasets.load_iris()\n",
    "input_data = iris_data.data\n",
    "X = pd.DataFrame(data=input_data, columns=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"])\n",
    "correct = iris_data.target\n",
    "y = pd.DataFrame(data=correct, columns=[\"Species\"])\n",
    "df = pd.concat([X, y], axis=1)\n",
    "df.drop(df.index[df[\"Species\"]==0], inplace=True)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# スクラッチしたtrain_test_splitでtrainとvalidationに分ける\n",
    "X_train, X_val, y_train, y_val = scratch_train_test_split(df.iloc[:, :-1].values, df.iloc[:, -1:].values, train_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (75, 4)\n",
      "X_val (25, 4)\n",
      "y_train (75,)\n",
      "y_val (25,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train\",X_train.shape)\n",
    "print(\"X_val\",X_val.shape)\n",
    "print(\"y_train\",y_train.shape)\n",
    "print(\"y_val\",y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 標準化\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_std = scaler.transform(X_train)\n",
    "X_val_std = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arisa/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2., 1., 2., 1., 1., 1., 1., 2., 2., 2., 2., 1., 1., 2., 2., 1., 1.,\n",
       "       1., 1., 2., 1., 2., 1., 1., 1.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学習と推定:ロジスティック回帰(勾配降下法を使用)\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgdc_model = SGDClassifier(loss=\"log\")\n",
    "sgdc_model.fit(X_train_std, y_train)\n",
    "y_val_pred = sgdc_model.predict(X_val_std)\n",
    "y_val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 1., 2., 1., 1., 1., 1., 2., 2., 2., 2., 1., 1., 2., 2., 1., 1.,\n",
       "       1., 1., 2., 1., 2., 1., 1., 1.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学習と推定:SVM\n",
    "from sklearn.svm import SVC\n",
    "svc_model = SVC()\n",
    "svc_model.fit(X_train_std, y_train)\n",
    "y_val_pred = svc_model.predict(X_val_std)\n",
    "y_val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 1., 2., 1., 1., 1., 1., 2., 2., 2., 2., 1., 1., 2., 2., 1., 1.,\n",
       "       1., 1., 2., 1., 2., 1., 1., 1.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学習と推定:決定木\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X_train_std, y_train)\n",
    "y_val_pred = dt_model.predict(X_val_std)\n",
    "y_val_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### シンプルデータセット1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# シンプルデータセット1作成\n",
    "np.random.seed(seed=0)\n",
    "n_samples = 500\n",
    "f0 = [-1, 2]\n",
    "f1 = [2, -1]\n",
    "cov = [[1.0,0.8], [0.8, 1.0]]\n",
    "f0 = np.random.multivariate_normal(f0, cov, int(n_samples/2))\n",
    "f1 = np.random.multivariate_normal(f1, cov, int(n_samples/2))\n",
    "X = np.concatenate((f0, f1))\n",
    "y = np.concatenate((np.ones((int(n_samples/2))), np.ones((int(n_samples/2))) *(-1))).astype(np.int)\n",
    "random_index = np.random.permutation(np.arange(n_samples))\n",
    "X = X[random_index]\n",
    "y = y[random_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# スクラッチしたtrain_test_splitでtrainとvalidationに分ける\n",
    "X_train, X_val, y_train, y_val = scratch_train_test_split(X, y, train_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 標準化\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_std = scaler.transform(X_train)\n",
    "X_val_std = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arisa/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1., -1., -1., -1., -1., -1.,  1., -1.,  1., -1.,  1.,  1.,  1.,\n",
       "       -1.,  1.,  1., -1., -1., -1.,  1., -1., -1.,  1.,  1., -1., -1.,\n",
       "       -1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
       "        1.,  1., -1., -1., -1.,  1., -1.,  1., -1.,  1., -1., -1., -1.,\n",
       "        1., -1.,  1., -1., -1.,  1., -1., -1., -1., -1., -1.,  1.,  1.,\n",
       "       -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1., -1.,\n",
       "        1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,\n",
       "        1.,  1., -1., -1., -1.,  1., -1.,  1., -1.,  1., -1., -1.,  1.,\n",
       "        1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1., -1.,  1., -1., -1.,\n",
       "        1.,  1.,  1., -1.,  1.,  1., -1., -1.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学習と推定:ロジスティック回帰(勾配降下法を使用)\n",
    "#from sklearn.linear_model import SGDClassifier\n",
    "sgdc_model = SGDClassifier(loss=\"log\")\n",
    "sgdc_model.fit(X_train_std, y_train)\n",
    "y_val_pred = sgdc_model.predict(X_val_std)\n",
    "y_val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1., -1., -1., -1., -1., -1.,  1., -1.,  1., -1.,  1.,  1.,  1.,\n",
       "       -1.,  1.,  1., -1., -1., -1.,  1., -1., -1.,  1.,  1., -1., -1.,\n",
       "       -1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
       "        1.,  1., -1., -1., -1.,  1., -1.,  1., -1.,  1., -1., -1., -1.,\n",
       "        1., -1.,  1., -1., -1.,  1., -1., -1., -1., -1., -1.,  1.,  1.,\n",
       "       -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1., -1.,\n",
       "        1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,\n",
       "        1.,  1., -1., -1., -1.,  1., -1.,  1., -1.,  1., -1., -1.,  1.,\n",
       "        1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1., -1.,  1., -1., -1.,\n",
       "        1.,  1.,  1., -1.,  1.,  1., -1., -1.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学習と推定:SVM\n",
    "#from sklearn.svm import SVC\n",
    "svc_model = SVC()\n",
    "svc_model.fit(X_train_std, y_train)\n",
    "y_val_pred = svc_model.predict(X_val_std)\n",
    "y_val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1., -1., -1., -1., -1., -1.,  1., -1.,  1., -1.,  1.,  1.,  1.,\n",
       "       -1.,  1.,  1., -1., -1., -1.,  1., -1., -1.,  1.,  1., -1., -1.,\n",
       "       -1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
       "        1.,  1., -1., -1., -1.,  1., -1.,  1., -1.,  1., -1., -1., -1.,\n",
       "        1., -1.,  1., -1., -1.,  1., -1., -1., -1., -1., -1.,  1.,  1.,\n",
       "       -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1., -1.,\n",
       "        1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,\n",
       "        1.,  1., -1., -1., -1.,  1., -1.,  1., -1.,  1., -1., -1.,  1.,\n",
       "        1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1., -1.,  1., -1., -1.,\n",
       "        1.,  1.,  1., -1.,  1.,  1., -1., -1.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学習と推定:決定木\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X_train_std, y_train)\n",
    "y_val_pred = dt_model.predict(X_val_std)\n",
    "y_val_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### シンプルデータセット2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# シンプルデータセット2作成\n",
    "X = np.array([[-0.44699 , -2.8073  ],[-1.4621  , -2.4586  ],\n",
    "       [ 0.10645 ,  1.9242  ],[-3.5944  , -4.0112  ],\n",
    "       [-0.9888  ,  4.5718  ],[-3.1625  , -3.9606  ],\n",
    "       [ 0.56421 ,  0.72888 ],[-0.60216 ,  8.4636  ],\n",
    "       [-0.61251 , -0.75345 ],[-0.73535 , -2.2718  ],\n",
    "       [-0.80647 , -2.2135  ],[ 0.86291 ,  2.3946  ],\n",
    "       [-3.1108  ,  0.15394 ],[-2.9362  ,  2.5462  ],\n",
    "       [-0.57242 , -2.9915  ],[ 1.4771  ,  3.4896  ],\n",
    "       [ 0.58619 ,  0.37158 ],[ 0.6017  ,  4.3439  ],\n",
    "       [-2.1086  ,  8.3428  ],[-4.1013  , -4.353   ],\n",
    "       [-1.9948  , -1.3927  ],[ 0.35084 , -0.031994],\n",
    "       [ 0.96765 ,  7.8929  ],[-1.281   , 15.6824  ],\n",
    "       [ 0.96765 , 10.083   ],[ 1.3763  ,  1.3347  ],\n",
    "       [-2.234   , -2.5323  ],[-2.9452  , -1.8219  ],\n",
    "       [ 0.14654 , -0.28733 ],[ 0.5461  ,  5.8245  ],\n",
    "       [-0.65259 ,  9.3444  ],[ 0.59912 ,  5.3524  ],\n",
    "       [ 0.50214 , -0.31818 ],[-3.0603  , -3.6461  ],\n",
    "       [-6.6797  ,  0.67661 ],[-2.353   , -0.72261 ],\n",
    "       [ 1.1319  ,  2.4023  ],[-0.12243 ,  9.0162  ],\n",
    "       [-2.5677  , 13.1779  ],[ 0.057313,  5.4681  ]])\n",
    "y = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
    "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# スクラッチしたtrain_test_splitでtrainとvalidationに分ける\n",
    "X_train, X_val, y_train, y_val = scratch_train_test_split(X, y, train_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 標準化\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_std = scaler.transform(X_train)\n",
    "X_val_std = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arisa/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学習と推定:ロジスティック回帰(勾配降下法を使用)\n",
    "#from sklearn.linear_model import SGDClassifier\n",
    "sgdc_model = SGDClassifier(loss=\"log\")\n",
    "sgdc_model.fit(X_train_std, y_train)\n",
    "y_val_pred = sgdc_model.predict(X_val_std)\n",
    "y_val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学習と推定:SVM\n",
    "#from sklearn.svm import SVC\n",
    "svc_model = SVC()\n",
    "svc_model.fit(X_train_std, y_train)\n",
    "y_val_pred = svc_model.predict(X_val_std)\n",
    "y_val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 1., 1., 0., 1., 1., 0., 0.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学習と推定:決定木\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X_train_std, y_train)\n",
    "y_val_pred = dt_model.predict(X_val_std)\n",
    "y_val_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】 回帰問題を解くコードの作成\n",
    "線形回帰(SGDRegressor)でHouse Pricesデータセット(GrLivAreaとYearBuilt)を学習・推定するコードを作成してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "index_array = df.columns\n",
    "index_list = index_array.tolist()\n",
    "index_list.remove(\"GrLivArea\")\n",
    "index_list.remove(\"YearBuilt\")\n",
    "index_list.remove(\"SalePrice\")\n",
    "df.drop(columns=index_list, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# スクラッチしたtrain_test_splitでtrainとvalidationに分ける\n",
    "X_train, X_val, y_train, y_val = scratch_train_test_split(df.iloc[:, :-1].values, df.iloc[:, -1:].values, train_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arisa/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# 標準化\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_std = scaler.transform(X_train)\n",
    "X_val_std = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arisa/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDRegressor'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([273097.57313455, 110629.42194599, 131631.1378898 , 105502.78054784,\n",
       "       222323.35646856, 154298.45093217, 125669.06742418, 347288.30662581,\n",
       "       238925.56630035, 216935.21904042, 207537.63798332, 238713.85403717,\n",
       "       120640.58347151, 147400.61239168, 148684.99969363, 232456.02758572,\n",
       "       103610.07381385, 124642.58450215, 198953.92967254, 170247.94504023,\n",
       "       235575.89525655, 132292.70629999, 157216.35693877, 160936.20353081,\n",
       "       246087.98034528,  67538.30338425, 178436.84200719, 191414.28321798,\n",
       "       202537.7672132 , 166565.9500541 , 272232.632972  , 243124.78013446,\n",
       "       111462.66945153, 348795.44043933, 108841.03160637, 191809.99247431,\n",
       "       272096.62392063, 174553.27109374,  98806.51793468, 167518.91132626,\n",
       "       286589.15371887, 163143.65527294,  90028.67629489, 192073.67006623,\n",
       "       138758.77980327, 122962.48794387, 134376.46688854, 101057.08231909,\n",
       "       145176.86536479, 122926.8178999 , 243834.33648642, 299483.44911954,\n",
       "        94908.8332984 , 198246.16914562, 218710.90574535, 254630.7575757 ,\n",
       "       195558.96442452, 136755.59772602, 185255.89786142, 188697.5674018 ,\n",
       "       227799.00283068,  90485.58930331, 186937.79024474, 210796.20844307,\n",
       "       154980.29201409, 132093.3119346 , 133964.46234744, 126296.76161543,\n",
       "       245432.57088399, 238007.37715966, 136925.48099633, 223381.91778449,\n",
       "       178683.32640183, 143334.3281345 ,  37945.82226825, 184306.91397623,\n",
       "       124605.63080877, 102875.8816663 , 175098.59094866, 240166.84096002,\n",
       "       204558.14248773, 209624.47804632, 264234.78985961, 166045.65173167,\n",
       "        63302.13585676, 117626.31584447, 172303.99035874, 284854.0123574 ,\n",
       "       195183.01566429,  47220.61008429, 226687.57827349, 150165.31614963,\n",
       "       222806.18892198, 211568.25219652, 163995.37962517, 193850.64042057,\n",
       "       191670.90394848, 104729.83888187, 132448.98802309, 203415.92318606,\n",
       "       135500.20934352, 138831.40354064, 259819.50063845, 143859.88749331,\n",
       "       117825.71020986, 228448.25334307, 222235.72109585, 151728.77841575,\n",
       "       211568.25219652, 203775.96239841, 157025.30308421, 235354.04665749,\n",
       "       133527.82201076, 195326.08157709, 243783.2690702 , 179278.43002355,\n",
       "       164649.89117394,  92273.97964293, 112441.16443179, 140452.99008439,\n",
       "       265211.10327794, 150353.67626664, 187311.04526741, 207855.46246591,\n",
       "       290287.44398976, 110706.02307032, 309659.23287899, 150840.48610703,\n",
       "       148392.32318226, 193573.74701834,  58087.473349  , 244406.98587448,\n",
       "       170926.7066477 , 185645.44816885, 206397.60024357,  67592.45027492,\n",
       "       166371.4309882 , 178398.99040128, 246084.90087083, 213100.91971815,\n",
       "        89684.03445478, 192918.33755705, 112592.57085541, 203775.96239841,\n",
       "       118610.96977362, 263319.68019336, 226776.49729562, 127550.35417289,\n",
       "       305527.38174586, 253317.75709119, 112346.08646077, 191393.62480935,\n",
       "       130277.20632494, 180966.48135577, 197375.07003418,  90289.27441237,\n",
       "       227891.00132726, 215557.93532937, 200365.98551504, 230538.17288052,\n",
       "       195297.46839453, 139667.73052062, 167002.59039079,  85622.62549708,\n",
       "        99953.61253584, 207370.83418745, 145560.25672333, 215719.47808886,\n",
       "       158187.79505762,  96864.9253464 ,  96963.98070439, 133901.97494595,\n",
       "       246189.2172652 , 213531.40110594, 114436.00599821, 211568.25219652,\n",
       "       228049.46461229, 303431.30325951, 217812.47710076, 153562.97513521,\n",
       "       128715.02770823, 206397.60024357, 221843.09131396, 199725.973426  ,\n",
       "       309855.54776993, 139231.98809645, 192398.93714713, 144478.34326122,\n",
       "       191159.4583125 , 214641.54201372, 101207.2050933 , 236638.04822255,\n",
       "       212474.12343942, 244026.67399039, 289468.31020705, 102023.25940156,\n",
       "       202826.08060071, 201822.05191234, 130144.27674801,  66490.26414108,\n",
       "       237780.26752423, 192073.67006623,  73798.82357325, 243653.41896772,\n",
       "       136279.30995839,  98103.12053162, 239768.95014176, 207136.6676906 ,\n",
       "       190023.39795973, 209472.17371018, 260344.16208474, 280510.06322419,\n",
       "       126200.78573189, 149989.65966731,  84437.67929002,  70398.08511322,\n",
       "       376004.42759399, 137641.19629719, 246430.44062346, 287700.57827606,\n",
       "       128091.31090395, 161907.64164965, 129310.13132996, 223230.51136087,\n",
       "       120596.5729167 , 223511.76788697, 287241.48370571, 150840.48610703,\n",
       "       187308.86370548, 149876.1048496 , 282937.56774034, 241081.95062626,\n",
       "       245891.66545434, 112817.49892891, 249653.34103924, 369193.71225059,\n",
       "       219908.5555871 , 118175.22734946, 181748.66144509, 106000.62463661,\n",
       "       199008.97447573, 100500.72821579, 243602.3515515 , 202341.45232226,\n",
       "       123800.99648579, 119045.42854838,  85399.87898551, 171198.72475045,\n",
       "       207943.48357551, 151300.47858989, 228581.18292   ,  77728.20086654,\n",
       "       267714.31100589, 127337.74399719, 146104.29292883, 247820.0422323 ,\n",
       "       214674.51832014, 157595.77091034, 234404.16485979, 109673.38119939,\n",
       "       246439.67904681, 251791.24851846, 216476.12447007, 239438.80776137,\n",
       "       199509.00012643, 168335.86354703, 227261.12557408, 192551.24148327,\n",
       "       236126.98832347, 162132.56972315, 259918.94173334, 224167.17734826,\n",
       "       240356.99690206, 101288.16934149, 230281.55215001, 160093.71760192,\n",
       "       226158.93944023, 194249.42915135, 221089.5244072 , 291225.00788966,\n",
       "       133670.88792355, 121644.61215988, 118873.74945303, 117825.71020986,\n",
       "       119846.08548439, 164106.75288095, 333636.97910704, 254865.82198507,\n",
       "       186439.94615597, 230304.00638367, 133404.13085718, 265112.04791995,\n",
       "        93490.618507  , 258813.67612505, 253443.6298067 , 240097.29669711,\n",
       "       132324.398957  , 232632.06980494, 321214.09617452, 183085.01407578,\n",
       "        91340.39312999, 163938.15326005, 179288.56635942, 169412.51597276,\n",
       "       149831.19638228, 120960.58951603, 107299.12566139, 296478.41991584,\n",
       "       235036.73435053,  97384.32575631, 262759.34870309, 240126.80779218,\n",
       "       141343.46395504, 112180.56631431,  85042.02133509, 181175.11414451,\n",
       "       142745.38346168, 220823.66525335, 261436.21188272, 164048.62860332,\n",
       "       161756.23522603,  61529.14288938, 131870.17968613, 239834.5170177 ,\n",
       "       260485.4321725 , 110628.52403347, 219386.07570274, 297412.00642878,\n",
       "       192164.77065029, 252566.37174636, 126875.56995239, 202930.39699508,\n",
       "       260742.05290301, 163085.5309953 , 189550.18966655, 139157.56853406,\n",
       "       167666.85253853, 290383.4198733 , 126964.48897452,  80396.92874094,\n",
       "       248603.12023414, 154274.7130491 , 129455.37880468, 149689.92629452,\n",
       "       358772.72774591, 227859.30867025, 120362.40641986, 143622.64152202,\n",
       "       323404.35471936,  66845.04231706, 155533.56664294, 143157.38800277,\n",
       "        88620.59783936, 299650.2529154 , 150794.29399029, 108387.1980724 ,\n",
       "       209767.54395911, 335379.56306682, 196714.78527341, 269876.8542807 ,\n",
       "       109450.63468782, 215738.85284807, 118873.74945303, 168985.11405942,\n",
       "       152521.09484093])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学習と推定:線形回帰（勾配降下法使用）\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "sgd_model = SGDRegressor()\n",
    "sgd_model.fit(X_train_std, y_train)\n",
    "y_val_pred = sgd_model.predict(X_val_std)\n",
    "y_val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
